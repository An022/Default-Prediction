{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# LOAD LIBRARIES\nimport pandas as pd, numpy as np # CPU libraries\nimport cupy, cudf # GPU libraries\nimport matplotlib.pyplot as plt, gc, os\n\nprint('RAPIDS version',cudf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-22T03:42:09.329254Z","iopub.execute_input":"2022-08-22T03:42:09.329808Z","iopub.status.idle":"2022-08-22T03:42:12.876872Z","shell.execute_reply.started":"2022-08-22T03:42:09.329693Z","shell.execute_reply":"2022-08-22T03:42:12.875572Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# TRAIN RANDOM SEED\nSEED = 42\n\n# # FILL NAN VALUE\n# NAN_VALUE = -127 # will fit in int8\n\n# FOLDS PER MODEL\nFOLDS = 5","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:42:12.879041Z","iopub.execute_input":"2022-08-22T03:42:12.879752Z","iopub.status.idle":"2022-08-22T03:42:12.889325Z","shell.execute_reply.started":"2022-08-22T03:42:12.879713Z","shell.execute_reply":"2022-08-22T03:42:12.886085Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **Read File**","metadata":{}},{"cell_type":"code","source":"TRAIN_PATH = '../input/pa-amex-default-reducing-dataset-size/train.parquet'","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:42:12.893145Z","iopub.execute_input":"2022-08-22T03:42:12.895332Z","iopub.status.idle":"2022-08-22T03:42:12.902464Z","shell.execute_reply.started":"2022-08-22T03:42:12.895286Z","shell.execute_reply":"2022-08-22T03:42:12.901338Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def read_file(path = '', usecols = None):\n    # LOAD DATAFRAME\n    if usecols is not None: df = cudf.read_parquet(path, columns=usecols)\n    else: df = cudf.read_parquet(path)\n\n    df = df.sort_values(['customer_ID','S_2'])\n    df = df.groupby(['customer_ID']).nth(-1).reset_index(drop=False)\n\n    print('shape of data:', df.shape)\n    \n    return df\n\nprint('Reading train data...')\ntrain = read_file(path = TRAIN_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:42:12.905647Z","iopub.execute_input":"2022-08-22T03:42:12.909262Z","iopub.status.idle":"2022-08-22T03:43:21.003685Z","shell.execute_reply.started":"2022-08-22T03:42:12.909223Z","shell.execute_reply":"2022-08-22T03:43:21.000814Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.004352Z","iopub.status.idle":"2022-08-22T03:43:21.004724Z","shell.execute_reply.started":"2022-08-22T03:43:21.004522Z","shell.execute_reply":"2022-08-22T03:43:21.004538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb\nprint('XGB Version',xgb.__version__)\n\nxgb_parms = { \n    'max_depth':4, \n    'learning_rate':0.05, \n    'subsample':0.8,\n    'colsample_bytree':0.6, \n    'eval_metric':'logloss',\n    'objective':'binary:logistic',\n    'tree_method':'gpu_hist',\n    'predictor':'gpu_predictor',\n    'random_state':0\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.006243Z","iopub.status.idle":"2022-08-22T03:43:21.006733Z","shell.execute_reply.started":"2022-08-22T03:43:21.006478Z","shell.execute_reply":"2022-08-22T03:43:21.006503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class IterLoadForDMatrix(xgb.core.DataIter):\n    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n        self.features = features\n        self.target = target\n        self.df = df\n        self.it = 0 # set iterator to 0\n        self.batch_size = batch_size\n        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n        super().__init__()\n\n    def reset(self):\n        '''Reset the iterator'''\n        self.it = 0\n\n    def next(self, input_data):\n        '''Yield next batch of data.'''\n        if self.it == self.batches:\n            return 0 # Return 0 when there's no more batch.\n        \n        a = self.it * self.batch_size\n        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n        dt = cudf.DataFrame(self.df.iloc[a:b])\n        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n        self.it += 1\n        return 1","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.008520Z","iopub.status.idle":"2022-08-22T03:43:21.010524Z","shell.execute_reply.started":"2022-08-22T03:43:21.010280Z","shell.execute_reply":"2022-08-22T03:43:21.010304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluation Metric**","metadata":{}},{"cell_type":"code","source":"def amex_metric_mod(y_true, y_pred):\n\n    labels     = np.transpose(np.array([y_true, y_pred]))\n    labels     = labels[labels[:, 1].argsort()[::-1]]\n    weights    = np.where(labels[:,0]==0, 20, 1)\n    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n\n    gini = [0,0]\n    for i in [1,0]:\n        labels         = np.transpose(np.array([y_true, y_pred]))\n        labels         = labels[labels[:, i].argsort()[::-1]]\n        weight         = np.where(labels[:,0]==0, 20, 1)\n        weight_random  = np.cumsum(weight / np.sum(weight))\n        total_pos      = np.sum(labels[:, 0] *  weight)\n        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n        lorentz        = cum_pos_found / total_pos\n        gini[i]        = np.sum((lorentz - weight_random) * weight)\n\n    return 0.5 * (gini[1]/gini[0] + top_four)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.011810Z","iopub.status.idle":"2022-08-22T03:43:21.012905Z","shell.execute_reply.started":"2022-08-22T03:43:21.012579Z","shell.execute_reply":"2022-08-22T03:43:21.012633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n\n    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n        df = (pd.concat([y_true, y_pred], axis='columns')\n              .sort_values('prediction', ascending=False))\n        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n        four_pct_cutoff = int(0.04 * df['weight'].sum())\n        df['weight_cumsum'] = df['weight'].cumsum()\n        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n        \n    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n        df = (pd.concat([y_true, y_pred], axis='columns')\n              .sort_values('prediction', ascending=False))\n        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n        total_pos = (df['target'] * df['weight']).sum()\n        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n        df['lorentz'] = df['cum_pos_found'] / total_pos\n        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n        return df['gini'].sum()\n\n    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n\n    g = normalized_weighted_gini(y_true, y_pred)\n    d = top_four_percent_captured(y_true, y_pred)\n\n    return 0.5 * (g + d)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.014269Z","iopub.status.idle":"2022-08-22T03:43:21.015345Z","shell.execute_reply.started":"2022-08-22T03:43:21.015094Z","shell.execute_reply":"2022-08-22T03:43:21.015118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training**","metadata":{}},{"cell_type":"code","source":"importances = []\noof = []\ntrain = train.to_pandas() # free GPU memory\nTRAIN_SUBSAMPLE = 1.0\ngc.collect()\n\nFEATURES = [x for x in train.columns.values if x not in ['customer_ID', 'target', 'S_2']]\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\nfor fold,(train_idx, valid_idx) in enumerate(skf.split(\n            train, train.target )):\n    \n    # Train with subtrain fold\n    if TRAIN_SUBSAMPLE<1.0:\n        np.random.seed(SEED)\n        train_idx = np.random.choice(train_idx, \n                       int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n        np.random.seed(None)\n    \n    print('#'*25)\n    print('### Fold',fold+1)\n    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n    print('#'*25)\n    \n    # For Fold K (Train, Valid, Test)\n    Xy_train = IterLoadForDMatrix(train.loc[train_idx], FEATURES, 'target')\n    X_valid = train.loc[valid_idx, FEATURES]\n    y_valid = train.loc[valid_idx, 'target']\n    \n    dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n    dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n    \n    # Train Model Fold K\n    model = xgb.train(xgb_parms, \n                dtrain=dtrain,\n                evals=[(dtrain,'train'),(dvalid,'valid')],\n                num_boost_round=9999,\n                early_stopping_rounds=100,\n                verbose_eval=100) \n    model.save_model(f'fold{fold}.xgb')\n    \n    # Get Feature Importance For Fold K\n    dd = model.get_score(importance_type='weight')\n    df = pd.DataFrame({'feature':dd.keys(),f'importance_{fold}':dd.values()})\n    importances.append(df)\n            \n    # Infer OOF Fold K\n    oof_preds = model.predict(dvalid)\n    y_pred=pd.DataFrame(data={'prediction':oof_preds})\n    y_true=pd.DataFrame(data={'target':y_valid.reset_index(drop=True)})\n    acc = amex_metric(y_true = y_true, y_pred = y_pred)\n    print('Evaluation Metric =',acc,'\\n')\n    \n    # SAVE OOF\n    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n    df['prediction'] = oof_preds\n    oof.append( df )\n    \n    del dtrain, Xy_train, dd, df\n    del X_valid, y_valid, dvalid, model\n    _ = gc.collect()\n    \nprint('#'*25)\noof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\n# acc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\nacc = amex_metric(oof['target'].to_frame(), oof['prediction'].to_frame())\nprint('OVERALL CV Evaluation Metric =',acc)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.018052Z","iopub.status.idle":"2022-08-22T03:43:21.018701Z","shell.execute_reply.started":"2022-08-22T03:43:21.018431Z","shell.execute_reply":"2022-08-22T03:43:21.018455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean\ndel train\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.020478Z","iopub.status.idle":"2022-08-22T03:43:21.021085Z","shell.execute_reply.started":"2022-08-22T03:43:21.020719Z","shell.execute_reply":"2022-08-22T03:43:21.020742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# **Out of Fold Prediction**","metadata":{}},{"cell_type":"code","source":"oof_xgb = pd.read_parquet(TRAIN_PATH, columns=['customer_ID']).drop_duplicates()\noof_xgb['customer_ID_hash'] = oof_xgb['customer_ID'].astype('int64')\noof_xgb = oof_xgb.set_index('customer_ID_hash')\noof_xgb = oof_xgb.merge(oof, left_index=True, right_index=True)\noof_xgb = oof_xgb.sort_index().reset_index(drop=True)\noof_xgb.to_csv(f'oof_xgb.csv',index=False)\noof_xgb.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.022979Z","iopub.status.idle":"2022-08-22T03:43:21.023492Z","shell.execute_reply.started":"2022-08-22T03:43:21.023215Z","shell.execute_reply":"2022-08-22T03:43:21.023237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# OOF Predictions\nplt.hist(oof_xgb.prediction.values, bins=100)\nplt.title('OOF Predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.025682Z","iopub.status.idle":"2022-08-22T03:43:21.026196Z","shell.execute_reply.started":"2022-08-22T03:43:21.025945Z","shell.execute_reply":"2022-08-22T03:43:21.025969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clear VRAM, RAM\ndel oof_xgb, oof\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.028462Z","iopub.status.idle":"2022-08-22T03:43:21.028995Z","shell.execute_reply.started":"2022-08-22T03:43:21.028706Z","shell.execute_reply":"2022-08-22T03:43:21.028729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Feature Importance**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndf = importances[0].copy()\nfor k in range(1,FOLDS): df = df.merge(importances[k], on='feature', how='left')\ndf['importance'] = df.iloc[:,1:].mean(axis=1)\ndf = df.sort_values('importance',ascending=False)\ndf.to_csv(f'xgb_feature_importance.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.031242Z","iopub.status.idle":"2022-08-22T03:43:21.031750Z","shell.execute_reply.started":"2022-08-22T03:43:21.031475Z","shell.execute_reply":"2022-08-22T03:43:21.031498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_FEATURES = 25\nplt.figure(figsize=(10,5*NUM_FEATURES//10))\nplt.barh(np.arange(NUM_FEATURES,0,-1), df.importance.values[:NUM_FEATURES], color = ['xkcd:sky blue'])\nplt.yticks(np.arange(NUM_FEATURES,0,-1), df.feature.values[:NUM_FEATURES])\nplt.title(f'XGB Feature Importance - Top {NUM_FEATURES}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.033712Z","iopub.status.idle":"2022-08-22T03:43:21.034354Z","shell.execute_reply.started":"2022-08-22T03:43:21.034058Z","shell.execute_reply":"2022-08-22T03:43:21.034082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ========================================\n# ================= Test =================\n# ========================================","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.036281Z","iopub.status.idle":"2022-08-22T03:43:21.036703Z","shell.execute_reply.started":"2022-08-22T03:43:21.036465Z","shell.execute_reply":"2022-08-22T03:43:21.036483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def read_file(path = '', usecols = None):\n#     # LOAD DATAFRAME\n#     if usecols is not None: df = cudf.read_parquet(path, columns=usecols)\n#     else: df = cudf.read_parquet(path)\n#     # REDUCE DTYPE FOR CUSTOMER AND DATE\n#     df['customer_ID'] = df['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n# #     df['customer_ID'] = df['customer_ID'].astype('int64')\n    \n#     df.S_2 = cudf.to_datetime( df.S_2 )\n#     # SORT BY CUSTOMER AND DATE (so agg('last') works correctly)\n#     #df = df.sort_values(['customer_ID','S_2'])\n#     #df = df.reset_index(drop=True)\n#     # FILL NAN\n# #     df = df.fillna(NAN_VALUE)\n#     print('shape of data:', df.shape)\n    \n#     return df\n\n# test = read_file(path = '../input/amex-data-integer-dtypes-parquet-format/test.parquet', usecols = ['customer_ID','S_2'])\n# test.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.041170Z","iopub.status.idle":"2022-08-22T03:43:21.041743Z","shell.execute_reply.started":"2022-08-22T03:43:21.041474Z","shell.execute_reply":"2022-08-22T03:43:21.041498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test[['customer_ID']].drop_duplicates(ignore_index = True).sort_index().values.flatten()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.043694Z","iopub.status.idle":"2022-08-22T03:43:21.044177Z","shell.execute_reply.started":"2022-08-22T03:43:21.043913Z","shell.execute_reply":"2022-08-22T03:43:21.043935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n#     chunk = len(customers)//NUM_PARTS\n#     if verbose != '':\n#         print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n#         print(f'There will be {chunk} customers in each part (except the last part).')\n#         print('Below are number of rows in each part:')\n#     rows = []\n\n#     for k in range(NUM_PARTS):\n#         if k==NUM_PARTS-1: cc = customers[k*chunk:]\n#         else: cc = customers[k*chunk:(k+1)*chunk]\n#         s = test.iloc[test.customer_ID.isin(cc)].shape[0]\n#         rows.append(s)\n#     if verbose != '': print( rows )\n#     return rows,chunk","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.046022Z","iopub.status.idle":"2022-08-22T03:43:21.046504Z","shell.execute_reply.started":"2022-08-22T03:43:21.046263Z","shell.execute_reply":"2022-08-22T03:43:21.046287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # customers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n# customers = test.drop_duplicates(subset=['customer_ID']).sort_index()\n# rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.055238Z","iopub.status.idle":"2022-08-22T03:43:21.056063Z","shell.execute_reply.started":"2022-08-22T03:43:21.055771Z","shell.execute_reply":"2022-08-22T03:43:21.055796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # CALCULATE SIZE OF EACH SEPARATE TEST PART\n\n# # COMPUTE SIZE OF 4 PARTS FOR TEST DATA\n# NUM_PARTS = 4\n# # TEST_PATH = '../input/amex-data-integer-dtypes-parquet-format/test.parquet'\n# TEST_PATH = '../input/pa-amex-default-reducing-dataset-size/test.parquet'\n\n\n# print(f'Reading test data...')\n# test = read_file(path = TEST_PATH, usecols = ['customer_ID','S_2'])\n# customers = test[['customer_ID']].drop_duplicates(ignore_index = True).sort_index().values.flatten()\n# rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.058282Z","iopub.status.idle":"2022-08-22T03:43:21.058780Z","shell.execute_reply.started":"2022-08-22T03:43:21.058514Z","shell.execute_reply":"2022-08-22T03:43:21.058537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # INFER TEST DATA IN PARTS\n# skip_rows = 0\n# skip_cust = 0\n# test_preds = []\n\n# for k in range(NUM_PARTS):\n    \n#     # READ PART OF TEST DATA\n#     print(f'\\nReading test data...')\n#     test = read_file(path = TEST_PATH)\n#     test = test.iloc[skip_rows:skip_rows+rows[k]]\n#     skip_rows += rows[k]\n#     print(f'=> Test part {k+1} has shape', test.shape )\n    \n#     # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n#     test = process_and_feature_engineer(test)\n#     if k==NUM_PARTS-1: test = test.loc[customers[skip_cust:]]\n#     else: test = test.loc[customers[skip_cust:skip_cust+num_cust]]\n#     skip_cust += num_cust\n    \n#     # TEST DATA FOR XGB\n#     X_test = test[FEATURES]\n#     dtest = xgb.DMatrix(data=X_test)\n#     test = test[['P_2_mean']] # reduce memory\n#     del X_test\n#     gc.collect()\n\n#     # INFER XGB MODELS ON TEST DATA\n#     model = xgb.Booster()\n#     model.load_model(f'XGB_v{VER}_fold0.xgb')\n#     preds = model.predict(dtest)\n#     for f in range(1,FOLDS):\n#         model.load_model(f'XGB_v{VER}_fold{f}.xgb')\n#         preds += model.predict(dtest)\n#     preds /= FOLDS\n#     test_preds.append(preds)\n\n#     # CLEAN MEMORY\n#     del dtest, model\n#     _ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T03:43:21.061026Z","iopub.status.idle":"2022-08-22T03:43:21.061538Z","shell.execute_reply.started":"2022-08-22T03:43:21.061257Z","shell.execute_reply":"2022-08-22T03:43:21.061310Z"},"trusted":true},"execution_count":null,"outputs":[]}]}